## ğŸ¯ Vision du Projet

**Nom de code :** EdgeOrchestra

**Objectif :** CrÃ©er une infrastructure open-source de federated learning et edge computing qui transforme des devices Apple inutilisÃ©s en cluster de calcul ML distribuÃ©.

## ğŸ“š Phase 0 : Research & State of the Art (Semaine 1)

**Papers essentiels Ã  lire :**
1. **Federated Learning:**
   - "Communication-Efficient Learning of Deep Networks from Decentralized Data" (Google, 2017) - le paper fondateur
   - "Federated Learning: Challenges, Methods, and Future Directions" (2019)
   - "FedAvg vs FedProx" - comparaison des algorithmes

2. **Edge Computing:**
   - "Edge Intelligence: Paving the Last Mile of AI with Edge Computing" (2019)
   - "In-Edge AI: Intelligentizing Mobile Edge Computing" (2020)

3. **Mobile ML:**
   - "MLPerf Mobile Inference Benchmark" - pour comprendre les perfs devices
   - Apple's Core ML performance papers

**Solutions existantes Ã  analyser :**
- Flower (framework federated learning)
- TensorFlow Federated
- PySyft
- FedML

**Ton angle de diffÃ©renciation :**
- Focus sur devices Apple (optimisations Metal/Core ML)
- Zero-config orchestration (plug & play)
- Battery-aware scheduling (crucial pour mobile)
- Hybrid edge-cloud (ton Hetzner comme fallback)

## ğŸ—ï¸ Architecture Technique

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    MacBook (Dev)                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Model Registry & Training Orchestrator     â”‚   â”‚
â”‚  â”‚  - Push models                               â”‚   â”‚
â”‚  â”‚  - Define federated tasks                    â”‚   â”‚
â”‚  â”‚  - Aggregate results                         â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           Raspberry Pi (Orchestrator)               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  - Device registry & health monitoring      â”‚   â”‚
â”‚  â”‚  - Task scheduler (battery/CPU aware)       â”‚   â”‚
â”‚  â”‚  - Model distribution                       â”‚   â”‚
â”‚  â”‚  - Gradient aggregation (FedAvg/FedProx)    â”‚   â”‚
â”‚  â”‚  - Communication coordinator                â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Redis: Task queue & state management       â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚              â”‚              â”‚
          â–¼              â–¼              â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ iPhone  â”‚    â”‚  iPad   â”‚    â”‚ iPhone  â”‚
    â”‚  Node   â”‚    â”‚  Node   â”‚    â”‚  Node   â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚ Worker  â”‚    â”‚ Worker  â”‚    â”‚ Worker  â”‚
    â”‚ Agent   â”‚    â”‚ Agent   â”‚    â”‚ Agent   â”‚
    â”‚         â”‚    â”‚         â”‚    â”‚         â”‚
    â”‚ Local   â”‚    â”‚ Local   â”‚    â”‚ Local   â”‚
    â”‚ Trainingâ”‚    â”‚ Trainingâ”‚    â”‚ Trainingâ”‚
    â”‚         â”‚    â”‚         â”‚    â”‚         â”‚
    â”‚ Battery â”‚    â”‚ Battery â”‚    â”‚ Battery â”‚
    â”‚ Monitor â”‚    â”‚ Monitor â”‚    â”‚ Monitor â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚  Hetzner (Optional) â”‚
              â”‚  - Cloud fallback   â”‚
              â”‚  - Model storage    â”‚
              â”‚  - Metrics DB       â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ› ï¸ Tech Stack

**Raspberry Pi (Orchestrator):**
- Python 3.11+
- FastAPI (API REST pour communication)
- Redis (task queue & state)
- PostgreSQL (metrics, historique)
- Docker (pour faciliter deployment)
- Prometheus + Grafana (monitoring)

**iPhone/iPad (Workers):**
- Swift + SwiftUI (app native)
- Core ML (inference optimisÃ©e)
- MLX ou TensorFlow Lite (training on-device)
- Background Tasks framework (training async)
- Network framework (communication efficace)

**MacBook (Control Plane):**
- Python (CLI tool)
- PyTorch (dÃ©finition & export modÃ¨les)
- Web dashboard (React/Next.js)

**Communication:**
- gRPC (efficace, bi-directionnel)
- Protocol Buffers (sÃ©rialisation)
- mDNS/Bonjour (dÃ©couverte automatique devices)

## ğŸ“‹ Roadmap DÃ©taillÃ©

### **Phase 1 : Foundation (Semaines 1-2)**

**Semaine 1 : Setup & Discovery**
- [ ] Commander Raspberry Pi 4 (8GB RAM recommandÃ©) + accessories
- [ ] Setup Raspberry Pi : OS, Docker, PostgreSQL, Redis
- [ ] ImplÃ©menter device discovery protocol (mDNS/Bonjour)
- [ ] CrÃ©er structure projet (monorepo recommended)
- [ ] DÃ©finir protocole de communication (Protocol Buffers schemas)

**Semaine 2 : Basic Communication**
- [ ] Serveur gRPC sur Raspberry Pi
- [ ] App iOS basique qui se connecte et s'enregistre
- [ ] Heartbeat system (devices ping orchestrator toutes les 30s)
- [ ] Device registry avec mÃ©tadonnÃ©es (model, iOS version, battery, etc.)
- [ ] Dashboard web basique (liste des devices connectÃ©s)

### **Phase 2 : Model Distribution (Semaines 3-4)**

**Semaine 3 : Model Management**
- [ ] Model registry sur Raspberry Pi
- [ ] API pour upload modÃ¨les depuis Mac (format Core ML)
- [ ] SystÃ¨me de versioning de modÃ¨les
- [ ] Compression de modÃ¨les pour transmission efficace
- [ ] Cache local sur devices

**Semaine 4 : Inference DistribuÃ©e**
- [ ] TÃ©lÃ©chargement & installation de modÃ¨les sur iOS
- [ ] ExÃ©cution d'infÃ©rence avec Core ML
- [ ] Envoi des rÃ©sultats Ã  l'orchestrateur
- [ ] Load balancing basique (round-robin)
- [ ] Metrics : latence, throughput, accuracy

### **Phase 3 : Federated Learning Core (Semaines 5-7)**

**Semaine 5 : Local Training**
- [ ] ImplÃ©menter training on-device (TensorFlow Lite ou MLX)
- [ ] Data loading depuis stockage local
- [ ] Gradient computation
- [ ] Test avec modÃ¨le simple (MNIST ou CIFAR-10 pour commencer)

**Semaine 6 : Federated Averaging**
- [ ] ImplÃ©mentation FedAvg sur orchestrateur
- [ ] AgrÃ©gation de gradients de multiples devices
- [ ] Update du modÃ¨le global
- [ ] Re-distribution aux clients
- [ ] Tests avec 2-3 devices simultanÃ©s

**Semaine 7 : Optimisations**
- [ ] Compression de gradients (quantization, sparsification)
- [ ] Differential privacy (ajout de bruit aux gradients)
- [ ] Secure aggregation (optionnel, cryptographie)
- [ ] Tests de convergence

### **Phase 4 : Battery & Resource Awareness (Semaines 8-9)**

**Semaine 8 : Smart Scheduling**
- [ ] Battery level monitoring sur iOS
- [ ] Thermal state monitoring
- [ ] Scheduler qui priorise devices avec >50% batterie
- [ ] Pause training si batterie <20%
- [ ] Background task scheduling (training pendant charge nocturne)

**Semaine 9 : Adaptive Learning**
- [ ] Profiling de perfs par device (temps/epoch, consommation)
- [ ] Adaptation taille batch selon device
- [ ] PrÃ©diction temps restant training
- [ ] Auto-scaling : plus de rounds si devices disponibles

### **Phase 5 : Advanced Features (Semaines 10-12)**

**Semaine 10 : Hybrid Edge-Cloud**
- [ ] IntÃ©gration Hetzner comme compute node additionnel
- [ ] Fallback automatique si pas assez de devices edge
- [ ] Cost optimization (edge first, cloud si nÃ©cessaire)
- [ ] Benchmark edge vs cloud (latence, coÃ»t, Ã©nergie)

**Semaine 11 : Advanced FL Algorithms**
- [ ] ImplÃ©mentation FedProx (gÃ¨re better heterogeneous devices)
- [ ] FedNova (normalisation pour convergence)
- [ ] Comparaison empirique FedAvg vs FedProx vs FedNova

**Semaine 12 : Production Ready**
- [ ] Error handling robuste (device disconnect, crash, etc.)
- [ ] Checkpointing & recovery
- [ ] Logging structurÃ©
- [ ] Documentation API
- [ ] Tests unitaires & intÃ©gration

## ğŸ“Š ExpÃ©rimentations & Metrics

**Use Cases Ã  implÃ©menter :**

1. **Image Classification (CIFAR-10)**
   - Dataset distribuÃ© sur devices
   - Mesure convergence vs centralized training
   - Impact nombre de devices sur accuracy finale

2. **Keyboard Prediction (Next-Word)**
   - Chaque device a typing patterns diffÃ©rents
   - Federated learning pour modÃ¨le global
   - Privacy-preserving (pas de partage de texte)

3. **Anomaly Detection**
   - Chaque device dÃ©tecte patterns locaux
   - ModÃ¨le global apprend de tous
   - Use case : dÃ©tection d'activitÃ© inhabituelle

**Metrics Ã  tracker :**
- **Performance ML :**
  - Accuracy vs rounds
  - Loss convergence
  - Time to convergence
  - Comparison centralized vs federated

- **System :**
  - Communication overhead (MB transmitted/round)
  - Latency per round
  - Energy consumption per device
  - Device participation rate

- **Scalability :**
  - Performance avec 1, 2, 3+ devices
  - Impact device heterogeneity
  - Stragglers handling

## ğŸ“ Deliverables Recherche

**Paper Structure (Ã  Ã©crire parallÃ¨lement) :**

1. **Introduction**
   - Motivation : recycling old devices for ML
   - Challenges : battery, heterogeneity, communication

2. **Related Work**
   - Federated learning frameworks
   - Edge ML systems
   - Mobile ML optimization

3. **System Design**
   - Architecture dÃ©taillÃ©e
   - Protocol design
   - Scheduling algorithms

4. **Implementation**
   - Tech stack choices & justifications
   - Challenges rencontrÃ©s
   - Optimizations

5. **Evaluation**
   - ExpÃ©riences sur 3 use cases
   - Comparaisons avec baselines
   - Ablation studies

6. **Discussion**
   - Limitations
   - Future work
   - Real-world applicability

**OÃ¹ soumettre :**
- ConfÃ©rences : MLSys, MobiCom, EdgeSys
- Workshops : FL-NeurIPS, TinyML Summit
- Journals : ACM TECS, IEEE IoT Journal

## ğŸ’¡ Innovations Potentielles (Differentiate ta recherche)

1. **Battery-Aware Federated Learning**
   - Algorithme qui balance convergence speed vs energy
   - Peut devenir une contribution novel

2. **Heterogeneity-Robust Aggregation**
   - iPhone 12 vs iPhone 7 ont perfs trÃ¨s diffÃ©rentes
   - Weighted aggregation selon device capability

3. **Opportunistic Training**
   - Learn from usage patterns (quand user charge device)
   - Maximize training sans impacter UX

4. **Privacy Metrics**
   - Quantifier privacy preservation
   - Trade-off utility vs privacy

## ğŸš€ Quick Wins pour Portfolio

**Demo Videos Ã  faire :**
1. "Zero-config setup : plug devices, they auto-discover"
2. "Live dashboard showing federated training in action"
3. "Battery drops, system pauses gracefully"
4. "Convergence comparison: federated vs centralized"

**GitHub Repo Structure :**
```
edge-orchestra/
â”œâ”€â”€ orchestrator/        # Raspberry Pi code
â”œâ”€â”€ ios-worker/         # iOS app
â”œâ”€â”€ control-plane/      # Mac CLI tool
â”œâ”€â”€ dashboard/          # Web monitoring
â”œâ”€â”€ experiments/        # Jupyter notebooks avec rÃ©sultats
â”œâ”€â”€ papers/            # LaTeX draft
â””â”€â”€ docs/              # Documentation
```

## ğŸ“ Bonus : Lien avec ton Stage

**Angles Ã  mentionner en entretien :**
- "J'ai implÃ©mentÃ© un systÃ¨me de federated learning from scratch"
- "J'ai gÃ©rÃ© l'hÃ©tÃ©rogÃ©nÃ©itÃ© des devices (key challenge en FL)"
- "J'ai optimisÃ© pour contraintes mobiles (batterie, compute)"
- "J'ai comparÃ© empiriquement diffÃ©rents algorithmes FL"
- "J'ai Ã©crit un paper technique sur mes findings"

**Questions qu'on te posera probablement :**
- Pourquoi federated learning vs centralized ?
- Comment gÃ©rer stragglers (slow devices) ?
- Communication efficiency : combien de MB par round ?
- Privacy guarantees : differential privacy implementation ?

---

## ğŸ¤” Questions pour toi avant de commencer :

1. **Tu veux que je dÃ©taille plus une phase en particulier ?** (ex: la partie iOS app, l'algorithme FedAvg, le monitoring, etc.)

2. **Tu as dÃ©jÃ  une idÃ©e du premier use case Ã  implÃ©menter ?** (je recommande MNIST pour commencer, c'est simple)

3. **Tu veux qu'on planifie les milestones de faÃ§on plus granulaire ?** (ex: objectifs semaine par semaine avec checklist prÃ©cise)

4. **Niveau hardware : tu veux commander le Raspberry Pi maintenant ou tu veux prototyper d'abord sans ?** (tu peux commencer avec juste iPhone + Mac pour tester la comm)

5. **Tu veux que je te fasse un starter code pour un composant en particulier ?** (ex: le gRPC server, l'app iOS basique, le FedAvg implementation)

Dis-moi ce qui t'aiderait le plus et on plonge dans les dÃ©tails ! ğŸš€